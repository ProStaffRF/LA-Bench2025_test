{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProStaffRF/LA-Bench2025_test/blob/main/baseline_3separte.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrV21bF8yUQL",
        "outputId": "27264859-d95e-4366-a392-7aadf34c0efa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Google Colaboratoryç’°å¢ƒã‚’æ¤œå‡ºã—ã¾ã—ãŸ\n",
            "\n",
            "ğŸ“¦ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\n",
            "âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\n",
            "\n",
            "ğŸ“¥ ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ä¸­: https://github.com/lasa-or-jp/la-bench.git\n",
            "âœ… ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³å®Œäº†: la-bench/\n",
            "\n",
            "ğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: /content/la-bench/la-bench/la-bench\n",
            "\n",
            "ğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ :\n",
            "total 420\n",
            "drwxr-xr-x  9 root root   4096 Nov  9 06:12 .\n",
            "drwxr-xr-x 11 root root   4096 Nov  9 06:12 ..\n",
            "drwxr-xr-x  2 root root   4096 Nov  9 06:12 announcements\n",
            "-rw-r--r--  1 root root   4741 Nov  9 06:12 CLAUDE.md\n",
            "drwxr-xr-x  4 root root   4096 Nov  9 06:12 code\n",
            "-rw-r--r--  1 root root   2658 Nov  9 06:12 CONTRIBUTING.md\n",
            "drwxr-xr-x  4 root root   4096 Nov  9 06:12 data\n",
            "drwxr-xr-x  3 root root   4096 Nov  9 06:12 docs\n",
            "drwxr-xr-x  8 root root   4096 Nov  9 06:12 .git\n",
            "drwxr-xr-x  3 root root   4096 Nov  9 06:12 .github\n",
            "-rw-r--r--  1 root root    979 Nov  9 06:12 .gitignore\n",
            "-rw-r--r--  1 root root   1101 Nov  9 06:12 LICENSE\n",
            "drwxr-xr-x  2 root root   4096 Nov  9 06:12 notebooks\n",
            "-rw-r--r--  1 root root    569 Nov  9 06:12 pyproject.toml\n",
            "-rw-r--r--  1 root root  12425 Nov  9 06:12 README.md\n",
            "-rw-r--r--  1 root root    121 Nov  9 06:12 requirements.txt\n",
            "-rw-r--r--  1 root root 346546 Nov  9 06:12 uv.lock\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: ç’°å¢ƒè¨­å®šã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
        "\"\"\"\n",
        "LA-Bench 2025: å®Ÿé¨“æ‰‹é †ç”Ÿæˆã‚¿ã‚¹ã‚¯\n",
        "Baseline Implementation for Google Colaboratory\n",
        "GitHub: https://github.com/lasa-or-jp/la-bench.git\n",
        "\"\"\"\n",
        "\n",
        "#@title 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— { display-mode: \"form\" }\n",
        "#@markdown ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¾ã™ã€‚\n",
        "\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Colabã‹ã©ã†ã‹ã®ç¢ºèª\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"âœ… Google Colaboratoryç’°å¢ƒã‚’æ¤œå‡ºã—ã¾ã—ãŸ\")\n",
        "    # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "    print(\"\\nğŸ“¦ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\")\n",
        "    !pip install -q openai pyyaml tqdm pandas\n",
        "\n",
        "    print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")\n",
        "\n",
        "    # GitHubãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³\n",
        "    REPO_URL = \"https://github.com/lasa-or-jp/la-bench.git\"\n",
        "    REPO_NAME = \"la-bench\"\n",
        "\n",
        "    if not os.path.exists(REPO_NAME):\n",
        "        print(f\"\\nğŸ“¥ ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ä¸­: {REPO_URL}\")\n",
        "        !git clone -q {REPO_URL}\n",
        "        print(f\"âœ… ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³å®Œäº†: {REPO_NAME}/\")\n",
        "    else:\n",
        "        print(f\"\\nğŸ“‚ ãƒªãƒã‚¸ãƒˆãƒªã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™: {REPO_NAME}/\")\n",
        "        print(\"ğŸ“¥ æœ€æ–°ç‰ˆã«æ›´æ–°ä¸­...\")\n",
        "        !cd {REPO_NAME} && git pull -q\n",
        "        print(\"âœ… æ›´æ–°å®Œäº†\")\n",
        "\n",
        "    # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š\n",
        "    WORK_DIR = Path(REPO_NAME)\n",
        "    os.chdir(WORK_DIR)\n",
        "    print(f\"\\nğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}\")\n",
        "\n",
        "    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ç¢ºèª\n",
        "    print(\"\\nğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ :\")\n",
        "    !ls -la\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"âš ï¸ ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®Ÿè¡Œä¸­ã§ã™\")\n",
        "    if Path.cwd().name == \"notebooks\":\n",
        "        os.chdir(Path.cwd().parent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PZr_6rXsyqlK",
        "outputId": "d21785e7-09b7-46f9-9f0e-2e67749f1563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”‘ OpenAI API Keyã‚’å…¥åŠ›: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "âœ… APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ\n",
            "ğŸ”‘ APIã‚­ãƒ¼: ********************Ct8A\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: OpenAI APIã‚­ãƒ¼ã®è¨­å®š\n",
        "#@title 2. OpenAI API Keyè¨­å®š { display-mode: \"form\" }\n",
        "#@markdown OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã‚­ãƒ¼ã¯å®‰å…¨ã«ç®¡ç†ã•ã‚Œã¾ã™ã€‚\n",
        "\n",
        "\n",
        "# APIã‚­ãƒ¼ã®å–å¾—æ–¹æ³•ã‚’é¸æŠ\n",
        "use_secrets = False  #@param {type:\"boolean\"}\n",
        "#@markdown â˜ï¸ Google Colab Secretsã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ãƒã‚§ãƒƒã‚¯\n",
        "\n",
        "if IN_COLAB:\n",
        "    import getpass\n",
        "    from google.colab import userdata\n",
        "    if use_secrets:\n",
        "        try:\n",
        "            # Colab Secretsã‹ã‚‰å–å¾—\n",
        "            API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "            print(\"âœ… APIã‚­ãƒ¼ã‚’Secretsã‹ã‚‰å–å¾—ã—ã¾ã—ãŸ\")\n",
        "        except Exception as e:\n",
        "            print(\"âš ï¸ Secretsã‹ã‚‰ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
        "            print(\"å·¦å´ã®ãƒ‘ãƒãƒ«ã®ğŸ”‘ã‚¢ã‚¤ã‚³ãƒ³ã‹ã‚‰'OPENAI_API_KEY'ã‚’è¨­å®šã—ã¦ãã ã•ã„\")\n",
        "            API_KEY = None\n",
        "    else:\n",
        "        # ç›´æ¥å…¥åŠ›\n",
        "        api_key_input = getpass.getpass(\"ğŸ”‘ OpenAI API Keyã‚’å…¥åŠ›: \")\n",
        "        if api_key_input:\n",
        "            API_KEY = api_key_input\n",
        "            os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "            print(\"âœ… APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ\")\n",
        "        else:\n",
        "            API_KEY = None\n",
        "            print(\"âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æ‰‹æ³•ã®ã¿ä½¿ç”¨ï¼‰\")\n",
        "else:\n",
        "    # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®å ´åˆ\n",
        "    API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not API_KEY:\n",
        "        API_KEY = input(\"OpenAI API Key: \")\n",
        "\n",
        "# APIã‚­ãƒ¼ã®æ¤œè¨¼\n",
        "if API_KEY:\n",
        "    print(f\"ğŸ”‘ APIã‚­ãƒ¼: {'*' * 20}{API_KEY[-4:]}\")\n",
        "else:\n",
        "    print(\"âš ï¸ GPTæ©Ÿèƒ½ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "71dPwmdnzEfP",
        "outputId": "703bfd61-7266-4005-fec2-caf8daef75d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "LA-Bench 2025 Baseline Implementation\n",
            "å®Ÿè¡Œç’°å¢ƒ: Google Colab\n",
            "å®Ÿè¡Œæ™‚åˆ»: 2025-11-09 06:12:40\n",
            "OpenAIåˆ©ç”¨å¯èƒ½: True\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨è¨­å®š\n",
        "#@title 3. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ { display-mode: \"form\" }\n",
        "\n",
        "import json\n",
        "import yaml\n",
        "import time\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Tuple, Set, Any\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿å‡¦ç†\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "# OpenAI API\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    OPENAI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPENAI_AVAILABLE = False\n",
        "    print(\"âš ï¸ OpenAIãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")\n",
        "\n",
        "# ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ (Colabå¯¾å¿œ)\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ãƒ­ã‚°è¨­å®š\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"LA-Bench 2025 Baseline Implementation\")\n",
        "print(f\"å®Ÿè¡Œç’°å¢ƒ: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "print(f\"å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"OpenAIåˆ©ç”¨å¯èƒ½: {OPENAI_AVAILABLE and API_KEY is not None}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0rypmgB20Yc2"
      },
      "outputs": [],
      "source": [
        "# Cell 4: ãƒ‡ãƒ¼ã‚¿æ§‹é€ \n",
        "#@title 4. ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å®šç¾© { display-mode: \"form\" }\n",
        "\n",
        "@dataclass\n",
        "class Step:\n",
        "    id: int\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class ReferenceEntry:\n",
        "    id: int\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class ExampleInput:\n",
        "    instruction: str\n",
        "    mandatory_objects: Set[str] = field(default_factory=set)\n",
        "    source_protocol_steps: List[Step] = field(default_factory=list)\n",
        "    expected_final_states: Set[str] = field(default_factory=set)\n",
        "    references: List[ReferenceEntry] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class ExampleOutput:\n",
        "    procedure_steps: List[Step] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class Measurement:\n",
        "    specific_criteria: Dict[str, int] = field(default_factory=dict)\n",
        "\n",
        "@dataclass\n",
        "class ExampleSample:\n",
        "    id: str\n",
        "    input: ExampleInput\n",
        "    output: ExampleOutput\n",
        "    measurement: Optional[Measurement] = None\n",
        "\n",
        "def _to_set(x):\n",
        "    return set(x) if isinstance(x, (list, set, tuple)) else set()\n",
        "\n",
        "def _to_list(x):\n",
        "    return list(x) if isinstance(x, (list, set, tuple)) else (x if isinstance(x, list) else [])\n",
        "\n",
        "def _to_steps(x) -> List[Step]:\n",
        "    steps: List[Step] = []\n",
        "    arr = _to_list(x)\n",
        "    if not arr:\n",
        "        return steps\n",
        "    if isinstance(arr[0], dict):\n",
        "        for it in arr:\n",
        "            try:\n",
        "                sid = int(it.get(\"id\", len(steps) + 1))\n",
        "            except Exception:\n",
        "                sid = len(steps) + 1\n",
        "            steps.append(Step(id=sid, text=str(it.get(\"text\", \"\")).strip()))\n",
        "    else:\n",
        "        for idx, s in enumerate(arr, start=1):\n",
        "            steps.append(Step(id=idx, text=str(s).strip()))\n",
        "    return steps\n",
        "\n",
        "def _to_references(x) -> List[ReferenceEntry]:\n",
        "    refs: List[ReferenceEntry] = []\n",
        "    arr = _to_list(x)\n",
        "    if not arr:\n",
        "        return refs\n",
        "    if isinstance(arr[0], dict):\n",
        "        for it in arr:\n",
        "            try:\n",
        "                rid = int(it.get(\"id\", len(refs) + 1))\n",
        "            except Exception:\n",
        "                rid = len(refs) + 1\n",
        "            refs.append(ReferenceEntry(id=rid, text=str(it.get(\"text\", \"\")).strip()))\n",
        "    else:\n",
        "        for idx, ref in enumerate(arr, start=1):\n",
        "            refs.append(ReferenceEntry(id=idx, text=str(ref).strip()))\n",
        "    return refs\n",
        "\n",
        "def parse_sample(obj: Dict[str, Any]) -> ExampleSample:\n",
        "    sid = obj.get(\"id\") or obj.get(\"sample_id\") or \"unknown\"\n",
        "    i = obj.get(\"input\", {})\n",
        "    o = obj.get(\"output\", {})\n",
        "    m = obj.get(\"measurement\", {})\n",
        "\n",
        "    # Measurement.specific_criteria ã‚’ dict ã«æ­£è¦åŒ–ï¼ˆlistå½¢å¼ã‚‚è¨±å®¹ï¼‰\n",
        "    sc_raw = m.get(\"specific_criteria\", {})\n",
        "    sc: Dict[str, int] = {}\n",
        "    if isinstance(sc_raw, dict):\n",
        "        for k, v in sc_raw.items():\n",
        "            try:\n",
        "                sc[str(k)] = int(v)\n",
        "            except Exception:\n",
        "                pass\n",
        "    elif isinstance(sc_raw, list):\n",
        "        for it in sc_raw:\n",
        "            try:\n",
        "                k = it.get(\"item\")\n",
        "                v = int(it.get(\"score\", 0))\n",
        "                if k:\n",
        "                    sc[str(k)] = v\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    sample = ExampleSample(\n",
        "        id=str(sid),\n",
        "        input=ExampleInput(\n",
        "            instruction=str(i.get(\"instruction\", \"\")).strip(),\n",
        "            mandatory_objects=_to_set(i.get(\"mandatory_objects\", [])),\n",
        "            source_protocol_steps=_to_steps(i.get(\"source_protocol_steps\", [])),\n",
        "            expected_final_states=_to_set(i.get(\"expected_final_states\", [])),\n",
        "            references=_to_references(i.get(\"references\", [])),\n",
        "        ),\n",
        "        output=ExampleOutput(\n",
        "            procedure_steps=_to_steps(o.get(\"procedure_steps\", []))\n",
        "        ),\n",
        "        measurement=Measurement(specific_criteria=sc) if sc else None\n",
        "    )\n",
        "    return sample\n",
        "\n",
        "def load_example_jsonl(path: str):\n",
        "    samples = []\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"JSONL not found: {p}\")\n",
        "    for line in p.read_text(encoding=\"utf-8\").splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        try:\n",
        "            obj = json.loads(line)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ JSONL parse error: {e}\")\n",
        "            continue\n",
        "        samples.append(parse_sample(obj))\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MXF0Ou0B6sFB",
        "outputId": "562f9187-7b20-4e00-ced1-cee11697be4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded 10 samples from data/public_test/public_test.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: JSONLãƒ­ãƒ¼ãƒ€ãƒ¼ã®åˆ©ç”¨\n",
        "#@title 5. JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ { display-mode: \"form\" }\n",
        "#@markdown exampleã‚’ä½¿ã†ã¨ãï¼š`data/example/example.jsonl`\n",
        "#@markdown public_testã‚’ä½¿ã†ã¨ãï¼š`data/public_test/public_test.jsonl`\n",
        "\n",
        "jsonl_path = 'data/public_test/public_test.jsonl'  #@param {type:'string'}\n",
        "\n",
        "try:\n",
        "    samples = load_example_jsonl(jsonl_path)\n",
        "    print(f'âœ… Loaded {len(samples)} samples from {jsonl_path}')\n",
        "except Exception as e:\n",
        "    print(f'âŒ Load error: {e}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "WZ94EpzOInJr",
        "outputId": "be215da4-7630-49ec-b680-4e7df03941e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¢ APIå‘¼ã³å‡ºã—ã‚’é–‹å§‹ã—ã¾ã™ã€‚å®Ÿè¡Œã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™...\n",
            "âœ… ç”Ÿæˆå®Œäº†: 10 samples\n",
            "ä¾‹: public_test_1 â†’ 19 steps\n",
            "ğŸ“„ Saved JSONL: outputs/runs/generated_20251109_062620.jsonl\n",
            "\n",
            "--- â¬‡ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œä¸­ ---\n",
            "ãƒ•ã‚¡ã‚¤ãƒ«å: generated_20251109_062620.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9638aa0b-7b9a-4d06-9823-d00a08ea823e\", \"generated_20251109_062620.jsonl\", 21480)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ã€‚ãŠä½¿ã„ã®PCã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: å®Ÿé¨“æ‰‹é †ã®ç”Ÿæˆï¼ˆOpenAI, Pydanticæ§‹é€ åŒ–ï¼‰\n",
        "#@title 6. LLMã§ Input ã‹ã‚‰ Outputï¼ˆprocedure_stepsï¼‰ã‚’ç”Ÿæˆ { display-mode: \"form\" }\n",
        "\n",
        "# --- å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Dict, Any, Set, Optional # å‹ãƒ’ãƒ³ãƒˆã®ãŸã‚\n",
        "import json # JSONLä¿å­˜ã«å¿…è¦\n",
        "from pathlib import Path # Pathã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¿…è¦\n",
        "import time # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«å¿…è¦\n",
        "from openai import OpenAI # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (Cell 5ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¸ˆã¿ã¨æƒ³å®š)\n",
        "\n",
        "# --- ğŸ§ª ãƒ¢ãƒ‡ãƒ«è¨­å®šã®æœ€é©åŒ– ---\n",
        "MODEL_NAME = \"gpt-4o-2024-08-06\" #@param [\"gpt-4.1-mini-2025-04-14\", \"gpt-4o-2024-08-06\", \"gpt-5-2025-08-07\", \"gpt-5-mini-2025-08-07\", \"gpt-5-nano-2025-08-07\"]\n",
        "TEMPERATURE = 0.1 # @param {type:\"number\"} <- å®‰å®šæ€§ã®ãŸã‚0.1ã«è¨­å®š\n",
        "\n",
        "#@markdown `build_messages`é–¢æ•°ã«ãŠã„ã¦ã€LLMã®å…¥åŠ›ã‚’è¨­è¨ˆã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "# --- Pydanticãƒ‡ãƒ¼ã‚¿æ§‹é€ ï¼ˆå¤‰æ›´ãªã—ï¼‰---\n",
        "class StepModel(BaseModel):\n",
        "    id: int = Field(ge=1, description=\"ã‚¹ãƒ†ãƒƒãƒ—ç•ªå·\")\n",
        "    text: str = Field(description=\"å®Ÿé¨“æ‰‹é †ã®è©³ç´°ãªèª¬æ˜\")\n",
        "\n",
        "class GeneratedOutput(BaseModel):\n",
        "    procedure_steps: List[StepModel] = Field(\n",
        "        description=\"å®Ÿé¨“æ‰‹é †ã®ãƒªã‚¹ãƒˆ\",\n",
        "        min_items=1,\n",
        "        max_items=50\n",
        "    )\n",
        "\n",
        "# --- ğŸ’¡ åˆ†é‡åˆ¥å³æ ¼åŒ–ä»•æ§˜æ›¸ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å®šç¾© (Specific Scoreå¼·åŒ–ç‰ˆ) ---\n",
        "\n",
        "MOLBIO_SPEC = \"\"\"\n",
        "## åˆ†å­ç”Ÿç‰©å­¦ãƒ—ãƒ­ãƒˆã‚³ãƒ«å³æ ¼åŒ–ä»•æ§˜æ›¸ (Specific Scoreå¼·åŒ–)\n",
        "I. è¨ˆæ¸¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨æ›–æ˜§è¡¨ç¾ã®å®šç¾©:\n",
        "- ãƒ«ãƒ¼ãƒ« 1.2.1: ã€Œã—ã°ã‚‰ãã€ã¯æ¨™æº–ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ™‚é–“ã¨ã—ã¦ 5.0 min ã‚’é©ç”¨ã™ã‚‹ã€‚\n",
        "- ãƒ«ãƒ¼ãƒ« 1.3.2: ã€Œæ°·ä¸Šã€ã¯ 4.0â„ƒï¼ˆè¨±å®¹ç¯„å›² 0.0ã€œ4.0â„ƒï¼‰ã®å†·å´ãƒ–ãƒ­ãƒƒã‚¯ã‚’å¼·åˆ¶ã™ã‚‹ã€‚\n",
        "- **[æ–°è¦S-1.4: å¸Œé‡ˆè¨ˆç”»]** ãƒ—ãƒ©ã‚¤ãƒãƒ¼ã‚„é«˜æ¿ƒåº¦æ ¸é…¸ã‚¹ãƒˆãƒƒã‚¯ï¼ˆ10 Î¼Mä»¥ä¸Šï¼‰ã‚’åå¿œã«ç”¨ã„ã‚‹å ´åˆã€**å¿…ãšä¸­é–“ã‚¹ãƒˆãƒƒã‚¯æ¿ƒåº¦ã¸ã®å¸Œé‡ˆï¼ˆä¾‹: 100 Î¼M â†’ 10 Î¼Mï¼‰ã®æ‰‹é †ã¨ã€ãã®å…·ä½“çš„ãªè¨ˆç®—**ã‚’æ˜è¨˜ã™ã‚‹ã“ã¨ã€‚\n",
        "- **[æ–°è¦S-1.5: æ¸¬å®šæ¡ä»¶]** UV/Visæ¸¬å®šï¼ˆ260 nmãªã©ï¼‰ã‚’è¡Œã†ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€ä½¿ç”¨ã™ã‚‹**æ¨™æº–ã‚»ãƒ«/ãƒ—ãƒ¬ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã€èª­ã¿å–ã‚Šãƒ¢ãƒ¼ãƒ‰ï¼ˆä¾‹: ãƒœãƒˆãƒ ãƒªãƒ¼ãƒ‰ï¼‰**ã€ãŠã‚ˆã³**æ¸¬å®šå‰ã®æ¶²é¢å‡ä¸€åŒ–æ‰‹é †ï¼ˆä¾‹: 5ç§’é–“ã®ä½é€Ÿæ··åˆï¼‰**ã‚’è©³ç´°ã«è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚\n",
        "\n",
        "II. æ“ä½œã®ç²’åº¦ã¨é †åºã®å³æ ¼åŒ–:\n",
        "- ãƒ«ãƒ¼ãƒ« 2.1.1: ã€Œæ·»åŠ ãƒ»æ··åˆã€ã¯ã€Pipette, Mix, Spin Down (500rcf) ã®3ã‚¹ãƒ†ãƒƒãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¼·åˆ¶çš„ã«åˆ†è§£ã•ã‚Œã‚‹ã€‚\n",
        "- **[æ–°è¦S-2.2: ãƒã‚¹ã‚¿ãƒ¼ãƒŸãƒƒã‚¯ã‚¹æ§‹æˆ]** ãƒã‚¹ã‚¿ãƒ¼ãƒŸãƒƒã‚¯ã‚¹èª¿è£½ã®æ‰‹é †ã§ã¯ã€**æœ€çµ‚çš„ãªå„æ§‹æˆè¦ç´ ã®æ¿ƒåº¦**ã¨**è¨ˆç®—ã«ä½¿ç”¨ã—ãŸã‚¹ãƒˆãƒƒã‚¯æ¿ƒåº¦**ã‚’æ‰‹é †ä¸­ã«ã‚«ãƒƒã‚³æ›¸ãã§è¨˜è¼‰ã™ã‚‹ã“ã¨ã‚’ç¾©å‹™ä»˜ã‘ã‚‹ã€‚\n",
        "\n",
        "III. å®‰å…¨ãƒ»ç’°å¢ƒã«é–¢ã™ã‚‹æš—é»™çŸ¥:\n",
        "- ãƒ«ãƒ¼ãƒ« 3.3.2: æ ¸é…¸ã‚’æ‰±ã†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œå‰å¾Œã«ã€ãƒ‡ãƒƒã‚­è¡¨é¢ã®UVé™¤æŸ“ã‚µã‚¤ã‚¯ãƒ«ã‚’å¼·åˆ¶çš„ã«æŒ¿å…¥ã™ã‚‹ã€‚\n",
        "\"\"\"\n",
        "\n",
        "BIOCHEM_SPEC = \"\"\"\n",
        "## ç”ŸåŒ–å­¦ãƒ»ã‚¿ãƒ³ãƒ‘ã‚¯è³ªç²¾è£½ãƒ—ãƒ­ãƒˆã‚³ãƒ«å³æ ¼åŒ–ä»•æ§˜æ›¸ (Specific Scoreå¼·åŒ–)\n",
        "I. æ¨™æº–çš„ãªè¨ˆæ¸¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨å˜ä½ã®å³æ ¼åŒ–:\n",
        "- ãƒ«ãƒ¼ãƒ« I.B: é å¿ƒåŠ›ã¯å¸¸ã«rcfå˜ä½ï¼ˆgï¼‰ã§è¨˜è¿°ã•ã‚Œãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚\n",
        "- ãƒ«ãƒ¼ãƒ« II.A: ã€Œä¸€æ™© (Overnight)ã€ã¯ 16 hours ã‚’å¼·åˆ¶ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã€è‡ªå‹•çš„ã« $4^{\\circ} \\text{C}$ ä½æ¸©ä¿æŒã‚’é€£çµã™ã‚‹ã€‚\n",
        "- **[æ–°è¦S-1.4: å›ºå½¢è©¦è–¬ã®æº¶è§£]** PEG 4000ã‚„é«˜åˆ†å­é‡åŒ–åˆç‰©ãªã©ã®å›ºå½¢è©¦è–¬ã®æº¶è§£ã¯ã€å˜ãªã‚‹ã€Œæ·»åŠ ã€ã§ã¯ãªãã€**æº¶è§£ã‚’ä¿è¨¼ã™ã‚‹ãŸã‚æœ€ä½15åˆ†é–“ã®ç©ã‚„ã‹ãªæ”ªæ‹Œ**ï¼ˆä¾‹: 500 rpm ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰ã‚’å¼·åˆ¶æŒ¿å…¥ã™ã‚‹ã€‚\n",
        "\n",
        "II. æ“ä½œã®ç²’åº¦ã¨é †åºã®è‡ªå‹•åŒ–è¦å‰‡:\n",
        "- ãƒ«ãƒ¼ãƒ« III.A: ã€Œè©¦è–¬ã‚’æ·»åŠ ã—ã€æ··åˆã™ã‚‹ã€ã¯ã€Aspirateã€Dispenseã€Mix_Actionã®3ã¤ã®ç‹¬ç«‹ã—ãŸLAã‚¹ãƒ†ãƒƒãƒ—ã«å³æ ¼ã«åˆ†è§£ã•ã‚Œã‚‹ã“ã¨ãŒå¼·åˆ¶ã•ã‚Œã‚‹ã€‚\n",
        "- **[æ–°è¦S-2.2: æ¸¬å®šå‰ã®QC]** å…‰å­¦çš„æ¸¬å®šï¼ˆBCAã€å¸å…‰åº¦ãªã©ï¼‰ã‚’è¡Œã†ç›´å‰ã«ã¯ã€**æ°—æ³¡ã®æœ‰ç„¡ã‚’ç¢ºèªï¼ˆVisual Checkï¼‰**ã—ã€ãã®å¾Œã®æ¸¬å®šã‚¹ãƒ†ãƒƒãƒ—ã«ã€Œæ°—æ³¡ãªã—ã®è¨˜éŒ² (QC Log)ã€ã‚’å¼·åˆ¶çš„ã«ä»˜éšã•ã›ã‚‹ã€‚\n",
        "\n",
        "III. å®‰å…¨æ€§ã€ç’°å¢ƒåˆ¶ç´„ã€ãŠã‚ˆã³æ©Ÿå™¨è¨­å®š:\n",
        "- ãƒ«ãƒ¼ãƒ« IV.A: å…¨ã¦ã®é…µç´ ã€æŠ—ä½“ã€ç²¾è£½ã‚¿ãƒ³ãƒ‘ã‚¯è³ªæº¶æ¶²ã¯ã€LAãƒ‡ãƒƒã‚­ä¸Šã§å¸¸ã«**4Â°Cä»¥ä¸‹ã®ã‚¯ãƒ¼ãƒªãƒ³ã‚°ãƒ–ãƒ­ãƒƒã‚¯**ã§ã®ä¿ç®¡ã‚’å¼·åˆ¶ã™ã‚‹ã€‚\n",
        "- **[æ–°è¦S-3.2: PPE]** å±é™ºè©¦è–¬ã®å–ã‚Šæ‰±ã„æ™‚ã«ã¯ã€æ‰‹é †ä¸­ã«**ã€Œæ‰‹è¢‹ã€ä¿è­·çœ¼é¡ã®ç€ç”¨ã‚’ç¢ºèªã€**ã¨ã„ã†å®‰å…¨ç¢ºèªã‚¹ãƒ†ãƒƒãƒ—ã‚’æ˜è¨˜ã™ã‚‹ã€‚\n",
        "\"\"\"\n",
        "\n",
        "BIOLOGY_SPEC = \"\"\"\n",
        "## ç”Ÿç‰©å®Ÿé¨“åˆ†é‡ã®è¦ç¯„çš„ãƒ«ãƒ¼ãƒ«ã‚»ãƒƒãƒˆ (Specific Scoreå¼·åŒ–)\n",
        "I. æ¨™æº–çš„ãªè¨ˆæ¸¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å³æ ¼ãªæ¨™æº–åŒ–ãƒ«ãƒ¼ãƒ«:\n",
        "- ãƒ«ãƒ¼ãƒ« 1.1.1: ã€Œã—ã°ã‚‰ãã€ã¯æ¨™æº–ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ™‚é–“ã¨ã—ã¦ 300ç§’ï¼ˆ5åˆ†ï¼‰ã‚’é©ç”¨ã™ã‚‹ã€‚\n",
        "- ãƒ«ãƒ¼ãƒ« 1.2.1: ç´°èƒãƒšãƒ¬ãƒƒãƒˆåŒ–ã®æ¨™æº–ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¡ä»¶ã¯ 150 x g ã§ 5 minutes ã‚’å¼·åˆ¶ã™ã‚‹ã€‚\n",
        "\n",
        "II. æ“ä½œã®ç²’åº¦ã¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®è‡ªå‹•åŒ–è¦å‰‡:\n",
        "- ãƒ«ãƒ¼ãƒ« 2.1.2: ã€Œç´°èƒã®çŠ¶æ…‹ã‚’ç¢ºèªã™ã‚‹ã€ã¯ã€è‡ªå‹•ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ³ã‚°ã«ã‚ˆã‚‹ã‚³ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚¹ $\\mathbf{\\ge 70\\%}$ ã®ç¢ºèªãªã©ã®å®šé‡çš„æ¸¬å®šã‚¹ãƒ†ãƒƒãƒ—ã«å¼·åˆ¶çš„ã«å¤‰æ›ã•ã‚Œã‚‹ã€‚\n",
        "- **[æ–°è¦S-2.4: ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿]** è‡ªå‹•ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆè›å…‰ã€æ˜è¦–é‡ï¼‰ã‚’è¡Œã†ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€ä½¿ç”¨ã™ã‚‹**ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚»ãƒƒãƒˆï¼ˆä¾‹: FITC/TRITCï¼‰**ã¨**éœ²å…‰æ™‚é–“ï¼ˆä¾‹: 50 msï¼‰**ã‚’å…·ä½“çš„ãªæ•°å€¤ã§è¨˜è¿°ã™ã‚‹ã“ã¨ã‚’ç¾©å‹™ä»˜ã‘ã‚‹ã€‚\n",
        "\n",
        "III. å®‰å…¨ãŠã‚ˆã³ç’°å¢ƒã«é–¢ã™ã‚‹æš—é»™çŸ¥ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«çµ„ã¿è¾¼ã¿:\n",
        "- ãƒ«ãƒ¼ãƒ« 3.1.1: ç´°èƒåŸ¹é¤Šé–¢é€£è©¦è–¬ã¯ã€æ·»åŠ ç›´å‰ã®æ¸©åº¦ã‚’ 37.0 Â± 0.5 Â°C ã«ç¶­æŒã™ã‚‹ã“ã¨ã‚’å¼·åˆ¶ã™ã‚‹ã€‚\n",
        "- **[æ–°è¦S-3.2: è©¦æ–™ãƒªã‚¹ã‚¯]** æ„ŸæŸ“ãƒªã‚¹ã‚¯ã®ã‚ã‚‹è©¦æ–™ï¼ˆä¾‹: ç‰¹å®šã®ç´°èƒæ ªã€ã‚¦ã‚¤ãƒ«ã‚¹ï¼‰ã‚’æ‰±ã†ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®å ´åˆã€ä½¿ç”¨ã™ã‚‹**è©¦é¨“æ©Ÿï¼ˆLAãƒ­ãƒœãƒƒãƒˆï¼‰ã®ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«**ã‚’æ‰‹é †æ›¸ã®å†’é ­ã«æ˜è¨˜ã™ã‚‹ã€‚\n",
        "\"\"\"\n",
        "\n",
        "ORGANIC_SPEC = \"\"\"\n",
        "## æœ‰æ©ŸåŒ–å­¦ãƒ©ãƒœã‚ªãƒ¼ãƒˆãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®ãŸã‚ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ç”Ÿæˆãƒ«ãƒ¼ãƒ« (Specific Scoreå¼·åŒ–)\n",
        "I. æ¨™æº–åŒ–ã•ã‚ŒãŸè¨ˆæ¸¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨æ›–æ˜§è¡¨ç¾ã®å³æ ¼ãªè¦å®š:\n",
        "- ãƒ«ãƒ¼ãƒ« 1.2.1: ã€Œçµ‚å¤œã€ã¯ $T_{\\text{overnight}} = 14$ æ™‚é–“ã‚’æ¨™æº–ã¨ã™ã‚‹ã€‚LAã¯ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³åˆ†æã®çµæœ (è»¢åŒ–ç‡ $X > 95\\%$) ã‚’å„ªå…ˆã™ã‚‹å‹•çš„èª¿æ•´ãƒ­ã‚¸ãƒƒã‚¯ã‚’å¼·åˆ¶ã™ã‚‹ã€‚\n",
        "- ãƒ«ãƒ¼ãƒ« 1.2.3: ã€Œã‚†ã£ãã‚Šæ»´ä¸‹ã€ã¯æ¨™æº–æ»´ä¸‹é€Ÿåº¦ $\\mathbf{0.5 \\sim 1.0 \\, \\text{mL/min}}$ ã®ç¯„å›²ã‚’æ¨™æº–ã¨ã™ã‚‹ã€‚\n",
        "\n",
        "II. æ“ä½œã®ç²’åº¦ã€é †åºåˆ¶å¾¡ã€ãŠã‚ˆã³æ¨™æº–çš„ãªå‰å‡¦ç†ãƒ—ãƒ­ãƒˆã‚³ãƒ«:\n",
        "- ãƒ«ãƒ¼ãƒ« 2.1.1: ã€Œæ·»åŠ ãƒ»æ··åˆã€ã¯ã€åˆ†æ³¨ã€ãƒãƒƒãƒ—æ´—æµ„/æ’å‡ºã€æ··åˆã®æœ€ä½3ã¤ã®åŸå­ã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†è§£ã™ã‚‹ã“ã¨ã‚’ç¾©å‹™ä»˜ã‘ã‚‹ã€‚\n",
        "\n",
        "III. å®‰å…¨ãƒ»ç’°å¢ƒã«é–¢ã™ã‚‹æš—é»™çŸ¥ã¨å®Ÿè¡Œåˆ¶ç´„:\n",
        "- ãƒ«ãƒ¼ãƒ« 3.1.3: æ°´/ç©ºæ°—æ„Ÿå—æ€§è©¦è–¬ã¯ã€åˆ†æ³¨ã‚¹ãƒ†ãƒƒãƒ—ã®å‰å¾Œ $\\mathbf{5}$ ç§’é–“ã€ãƒãƒƒãƒ—å…ˆç«¯ã«ä¸æ´»æ€§ã‚¬ã‚¹ï¼ˆ$\\text{N}_{2}$ï¼‰ã®ä¿è­·ã‚·ãƒ¼ãƒ«ãƒ‰ã‚’å¹ãä»˜ã‘ã‚‹**ã€Œã‚¬ã‚¹ã‚·ãƒ¼ãƒ«ãƒ‰åˆ†æ³¨ã€**ã‚’å¼·åˆ¶çš„ã«æŒ¿å…¥ã™ã‚‹ã€‚\n",
        "- **[æ–°è¦S-3.4: å»ƒæ£„ç‰©è¨˜éŒ²]** å»ƒæ£„ç‰©å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€å»ƒæ£„ç‰©å®¹å™¨ã®ã€Œåå¿œå±¥æ­´ã‚¯ãƒ©ã‚¹ã€ã¨**æ’å‡ºé‡ï¼ˆgã¾ãŸã¯mLï¼‰**ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ã™ã‚‹ã“ã¨ã‚’ç¾©å‹™ä»˜ã‘ã‚‹ã€‚\n",
        "\"\"\"\n",
        "\n",
        "INORGANIC_SPEC = \"\"\"\n",
        "## ç„¡æ©ŸåŒ–å­¦å®Ÿé¨“åˆ†é‡ã«ãŠã‘ã‚‹æš—é»™çŸ¥ã®æŠ½å‡ºã¨æ•°å€¤åŒ–ä»•æ§˜æ›¸ (Specific Scoreå¼·åŒ–)\n",
        "I. æ¨™æº–çš„ãªè¨ˆæ¸¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨æ›–æ˜§è¡¨ç¾ã®æ•°å€¤çš„å®šç¾©:\n",
        "- ãƒ«ãƒ¼ãƒ« 1.1.3: æ¿ƒåº¦ã®æ¨™æº–åŒ–: $\\text{ppm}$ ã¯åˆ†å­é‡ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã $\\text{M}$ ã¸ã®**å‹•çš„æ›ç®—**ã‚’å†…éƒ¨ã§è¡Œã†ã“ã¨ã‚’ç¾©å‹™ä»˜ã‘ã‚‹ã€‚\n",
        "\n",
        "II. æ“ä½œã®åŸå­åˆ†è§£ã¨ãƒ—ãƒ­ãƒˆã‚³ãƒ«é †åºã®å³æ ¼åŒ–:\n",
        "- ãƒ«ãƒ¼ãƒ« 2.3: æ¶²-æ¶²æŠ½å‡ºã¯ã€å¸å¼•å‰ã«**$120 \\text{ s}$ ä»¥ä¸Šã®å¼·åˆ¶é™ç½®ã‚¹ãƒ†ãƒƒãƒ—**ã‚’çµ„ã¿è¾¼ã‚€ã€‚\n",
        "\n",
        "III. å®‰å…¨ãƒ»ç’°å¢ƒã«é–¢ã™ã‚‹æš—é»™çŸ¥ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«çµ„ã¿è¾¼ã¿:\n",
        "- ãƒ«ãƒ¼ãƒ« 3.1.2: ç™ºç†±åå¿œæ™‚ã®å¼·åˆ¶æ°·æµ´: æ¿ƒç¡«é…¸ã‚„é«˜æ¿ƒåº¦æ°´é…¸åŒ–ç‰©æº¶æ¶²ã®æ··åˆã¯ã€**$0^\\circ \\text{C}$ ã‹ã‚‰ $4^\\circ \\text{C}$ ã®æ°·æµ´**ä¸­ã§è¡Œã†ã“ã¨ã‚’å¼·åˆ¶ã™ã‚‹ã€‚\n",
        "\"\"\"\n",
        "\n",
        "# --- ğŸ’¡ å…¨ä»•æ§˜æ›¸ã‚’æ ¼ç´ã™ã‚‹ãƒã‚¹ã‚¿ãƒ¼è¾æ›¸ ---\n",
        "ALL_FIELD_SPECS = {\n",
        "    \"åˆ†å­ç”Ÿç‰©å­¦\": MOLBIO_SPEC,\n",
        "    \"ç”ŸåŒ–å­¦ãƒ»ã‚¿ãƒ³ãƒ‘ã‚¯è³ªç²¾è£½\": BIOCHEM_SPEC,\n",
        "    \"ç”Ÿç‰©å®Ÿé¨“\": BIOLOGY_SPEC,\n",
        "    \"æœ‰æ©ŸåŒ–å­¦\": ORGANIC_SPEC,\n",
        "    \"ç„¡æ©ŸåŒ–å­¦\": INORGANIC_SPEC,\n",
        "}\n",
        "\n",
        "# --- ğŸ’¡ åˆ†é‡ç‰¹å®šé–¢æ•°ã®å®šç¾©ï¼ˆå¤‰æ›´ãªã—ï¼‰ ---\n",
        "def classify_experiment_field(instruction: str) -> str:\n",
        "    \"\"\"å®Ÿé¨“æŒ‡ç¤ºã«å«ã¾ã‚Œã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ãã€é©ç”¨ã™ã¹ãå°‚é–€åˆ†é‡ã‚’ç‰¹å®šã™ã‚‹\"\"\"\n",
        "    instruction_lower = instruction.lower()\n",
        "\n",
        "    # 1. ç”Ÿç‰©å®Ÿé¨“ (ç´°èƒã€åŸ¹é¤Š) ã‚’æœ€å„ªå…ˆã«ãƒã‚§ãƒƒã‚¯\n",
        "    if any(keyword in instruction_lower for keyword in [\"ç´°èƒ\", \"åŸ¹åœ°\", \"åŸ¹é¤Š\", \"ç¶™ä»£\", \"ãƒˆãƒªãƒ—ã‚·ãƒ³\", \"ã‚³ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚¹\", \"ã‚¦ã‚§ãƒ«\", \"ã‚¤ãƒ³ã‚­ãƒ¥ãƒ™ãƒ¼ãƒˆ\"]):\n",
        "        return \"ç”Ÿç‰©å®Ÿé¨“\"\n",
        "\n",
        "    # 2. æœ‰æ©ŸåŒ–å­¦ã‚’ãƒã‚§ãƒƒã‚¯ (åˆæˆã€æº¶åª’ã€ä¸æ´»æ€§é›°å›²æ°—ãªã©)\n",
        "    elif any(keyword in instruction_lower for keyword in [\"åˆæˆ\", \"æœ‰æ©Ÿ\", \"é‚„æµ\", \"è§¦åª’\", \"æº¶åª’\", \"åŠ ç†±\", \"æ»´ä¸‹\", \"ä¸æ´»æ€§\", \"ã‚°ãƒ­ãƒ¼ãƒ–ãƒœãƒƒã‚¯ã‚¹\"]):\n",
        "        return \"æœ‰æ©ŸåŒ–å­¦\"\n",
        "\n",
        "    # 3. ç„¡æ©ŸåŒ–å­¦ã‚’ãƒã‚§ãƒƒã‚¯ (æ²ˆæ®¿ã€é‡‘å±ã€é…¸/å¡©åŸºã€ãƒ¢ãƒ«é‡è¨ˆç®—ã€æ¥µå¾®é‡)\n",
        "    elif any(keyword in instruction_lower for keyword in [\"ç„¡æ©Ÿ\", \"éŒ¯ä½“\", \"æ²ˆæ®¿\", \"é‡‘å±\", \"æ¯”è‰²\", \"ppm\", \"ppb\", \"é…¸\", \"å¡©åŸº\", \"æ°´é…¸åŒ–ç‰©\", \"ã‚¬ã‚¹å®šé‡\"]):\n",
        "        return \"ç„¡æ©ŸåŒ–å­¦\"\n",
        "\n",
        "    # 4. ç”ŸåŒ–å­¦ãƒ»ã‚¿ãƒ³ãƒ‘ã‚¯è³ªç²¾è£½ã‚’ãƒã‚§ãƒƒã‚¯\n",
        "    elif any(keyword in instruction_lower for keyword in [\"ã‚¿ãƒ³ãƒ‘ã‚¯è³ª\", \"ç²¾è£½\", \"ã‚¢ãƒƒã‚»ã‚¤\", \"bca\", \"ã‚¯ãƒ­ãƒãƒˆ\", \"é€æ\", \"å¤‰æ€§\", \"ã‚«ãƒ©ãƒ \", \"SDS-PAGE\", \"é…µç´ \"]):\n",
        "        return \"ç”ŸåŒ–å­¦ãƒ»ã‚¿ãƒ³ãƒ‘ã‚¯è³ªç²¾è£½\"\n",
        "\n",
        "    # 5. åˆ†å­ç”Ÿç‰©å­¦ã‚’ãƒã‚§ãƒƒã‚¯\n",
        "    elif any(keyword in instruction_lower for keyword in [\"dna\", \"rna\", \"pcr\", \"ãƒ—ãƒ©ã‚¤ãƒãƒ¼\", \"é›»æ°—æ³³å‹•\", \"æ ¸é…¸\", \"åˆ¶é™é…µç´ \"]):\n",
        "        return \"åˆ†å­ç”Ÿç‰©å­¦\"\n",
        "\n",
        "    # 6. ã©ã®åˆ†é‡ã«ã‚‚ãƒãƒƒãƒã—ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ†é‡\n",
        "    return \"ç”ŸåŒ–å­¦ãƒ»ã‚¿ãƒ³ãƒ‘ã‚¯è³ªç²¾è£½\"\n",
        "\n",
        "# --- ğŸ’¡ build_messages é–¢æ•°ã®ä¿®æ­£ï¼ˆå‹•çš„é¸æŠãƒ­ã‚¸ãƒƒã‚¯ï¼‰ ---\n",
        "def build_messages(sample: ExampleSample) -> list[dict]:\n",
        "\n",
        "    # --- ä¿®æ­£å¾Œã®åŸºæœ¬ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (è¨ˆç”»æ€§ã¨å®‰å…¨æ€§ã®å¼·åˆ¶) ---\n",
        "    base_sys_prompt = (\n",
        "        \"ã‚ãªãŸã¯ã€åŒ–å­¦ã€ç”Ÿç‰©å­¦ã€ãŠã‚ˆã³ææ–™ç§‘å­¦ã‚’å«ã‚€å…¨åˆ†é‡ã®**ãƒ©ãƒœã‚ªãƒ¼ãƒˆãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ (LA) ãƒ—ãƒ­ãƒˆã‚³ãƒ«å¤‰æ›ã®æœ€é«˜å°‚é–€å®¶**ã§ã™ã€‚\"\n",
        "        \"ã‚ãªãŸã®å”¯ä¸€ã®ä»»å‹™ã¯ã€æä¾›ã•ã‚ŒãŸ Input ã‚’èª­ã¿è¾¼ã¿ã€LAã‚·ã‚¹ãƒ†ãƒ ãŒå®Ÿè¡Œå¯èƒ½ãª**æ¥µã‚ã¦å³æ ¼ã§è©³ç´°ãªå®Ÿé¨“æ‰‹é †**ï¼ˆprocedure_stepsï¼‰ã‚’è¿”ã™ã“ã¨ã§ã™ã€‚\"\n",
        "        \"æœ€é‡è¦åˆ¶ç´„: å‡ºåŠ›ã¯ã€Pydanticã‚¹ã‚­ãƒ¼ãƒã«å³æ ¼ã«æº–æ‹ ã—ãŸ**JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿**ã§ã‚ã‚Šã€ã„ã‹ãªã‚‹èª¬æ˜ã‚„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚‚è¨±ã•ã‚Œã¾ã›ã‚“ã€‚\"\n",
        "        \"åˆ¶ç´„: ã‚¹ãƒ†ãƒƒãƒ—æ•°ã¯æœ€å¤§50ã€å„ã‚¹ãƒ†ãƒƒãƒ—ã¯10æ–‡ä»¥ä¸‹ã€idã¯1ã‹ã‚‰æ˜‡é †ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚\"\n",
        "\n",
        "        # --- â˜… Specific Scoreå¯¾ç­–ã®å…¨åˆ†é‡å…±é€šãƒ«ãƒ¼ãƒ« â˜… ---\n",
        "        \"\\n\\n### å…¨åˆ†é‡å…±é€šã®å®Ÿè¡Œå‰è¨ˆç”»ãŠã‚ˆã³å“è³ªç®¡ç† (Specific Scoreå„ªå…ˆ)\"\n",
        "        \"A. **è¨ˆç”»ã¨è¨ˆç®—ã®æ˜ç¤º**: è¤‡é›‘ãªè©¦è–¬ï¼ˆãƒã‚¹ã‚¿ãƒ¼ãƒŸãƒƒã‚¯ã‚¹ã€å¸Œé‡ˆæ¶²ï¼‰èª¿è£½ã‚’è¡Œã†ã‚¹ãƒ†ãƒƒãƒ—ã®ç›´å‰ã«ã¯ã€**å¿…è¦ãªæœ€çµ‚å®¹é‡ã¨å„è©¦è–¬ã®ã‚¹ãƒˆãƒƒã‚¯æ¿ƒåº¦ã‹ã‚‰ã®å…·ä½“çš„ãªè¨ˆç®—æ‰‹é †**ã‚’ã€**å¿…ãš**æ‰‹é †æ›¸ã«ç››ã‚Šè¾¼ã‚€ã“ã¨ã€‚\"\n",
        "        \"B. **ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®åˆ†è§£**: å®Ÿé¨“é–‹å§‹æ™‚ã€ã‚µãƒ³ãƒ—ãƒ«ã®åˆæœŸå®¹å™¨ã‹ã‚‰LAã‚·ã‚¹ãƒ†ãƒ ã®ä½¿ç”¨ã™ã‚‹æ–°ã—ã„å®¹å™¨ï¼ˆãƒã‚¤ã‚¯ãƒ­ãƒãƒ¥ãƒ¼ãƒ–ãªã©ï¼‰ã¸ã®ç§»å‹•ã¯ã€å¿…ãš**å€‹åˆ¥ã®æ‰‹é †**ã¨ã—ã¦è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚\"\n",
        "        \"C. **PPEã¨å®‰å…¨æ€§**: å…¨ã¦ã®æ“ä½œã¯ã€**é©åˆ‡ãªPPEï¼ˆä¾‹: æ‰‹è¢‹ã€ä¿è­·çœ¼é¡ï¼‰ã®ç€ç”¨**ã‹ã‚‰é–‹å§‹ã—ã€å±é™ºç‰©ï¼ˆæº¶åª’ã€é…¸ï¼‰ã®æ“ä½œæ™‚ã«ã¯**ãƒ‰ãƒ©ãƒ•ãƒˆï¼ˆLEVï¼‰ã®ç¢ºèª**ã‚’æ‰‹é †ã«çµ„ã¿è¾¼ã‚€ã“ã¨ã€‚\"\n",
        "    )\n",
        "\n",
        "    # 1. å®Ÿé¨“æŒ‡ç¤ºã‹ã‚‰åˆ†é‡ã‚’ç‰¹å®š\n",
        "    identified_field = classify_experiment_field(sample.input.instruction)\n",
        "\n",
        "    # 2. é–¢é€£ã™ã‚‹å³æ ¼ä»•æ§˜æ›¸ã‚’ãƒã‚¹ã‚¿ãƒ¼è¾æ›¸ã‹ã‚‰å–å¾—\n",
        "    FIELD_SPECIFICATION = ALL_FIELD_SPECS.get(identified_field, \"\")\n",
        "\n",
        "    # 3. åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ä»•æ§˜æ›¸ã‚’çµåˆ\n",
        "    if FIELD_SPECIFICATION:\n",
        "        augmented_sys_prompt = base_sys_prompt + (\n",
        "            f\"\\n\\n### å°‚é–€åˆ†é‡ãƒ—ãƒ­ãƒˆã‚³ãƒ«å³æ ¼åŒ–ä»•æ§˜æ›¸ - å®Ÿè¡Œç¾©å‹™: {identified_field} \\n\"\n",
        "            \"ã‚ãªãŸã¯ã€ã“ã®ä»•æ§˜æ›¸ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹**ã™ã¹ã¦ã®ãƒ«ãƒ¼ãƒ«ã¨å…·ä½“çš„ãªæ•°å€¤å®šç¾©ã‚’æœ€å„ªå…ˆã§é©ç”¨**ã—ã€æ›–æ˜§ãªæŒ‡ç¤ºã‚’ä»•æ§˜æ›¸ã«å¾“ã£ã¦**å¼·åˆ¶çš„ã«æ•°å€¤ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¤‰æ›**ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\\n\"\n",
        "            f\"\\n{FIELD_SPECIFICATION}\" # é¸æŠã•ã‚ŒãŸä»•æ§˜æ›¸å…¨ä½“ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æŒ¿å…¥\n",
        "        )\n",
        "    else:\n",
        "        # ä»•æ§˜æ›¸ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ä¿®æ­£ã•ã‚ŒãŸåŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã‚’ä½¿ç”¨\n",
        "        augmented_sys_prompt = base_sys_prompt\n",
        "\n",
        "    # 4. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (usr) ã®ä½œæˆï¼ˆå¤‰æ›´ãªã—ï¼‰\n",
        "    user_lines = []\n",
        "    user_lines.append(f\"ã€å®Ÿé¨“æŒ‡ç¤ºã€‘\\n{sample.input.instruction}\")\n",
        "\n",
        "    if sample.input.mandatory_objects:\n",
        "        user_lines.append(\"\\nã€ä½¿ç”¨ã™ã‚‹ç‰©å“ã€‘\")\n",
        "        for it in sorted(sample.input.mandatory_objects):\n",
        "            user_lines.append(f\"- {it}\")\n",
        "    if sample.input.source_protocol_steps:\n",
        "        user_lines.append(\"\\nã€å…ƒãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®æ‰‹é †ï¼ˆå‚è€ƒï¼‰ã€‘\")\n",
        "        for st in sample.input.source_protocol_steps:\n",
        "            user_lines.append(f\"- {st.id}. {st.text}\")\n",
        "    if sample.input.expected_final_states:\n",
        "        user_lines.append(\"\\nã€æœŸå¾…ã•ã‚Œã‚‹æœ€çµ‚çŠ¶æ…‹ã€‘\")\n",
        "        for fs in sorted(sample.input.expected_final_states):\n",
        "            user_lines.append(f\"- {fs}\")\n",
        "    if sample.input.references:\n",
        "        user_lines.append(\"\\nã€å‚è€ƒæ–‡çŒ®ã€‘\")\n",
        "        for ref in sample.input.references:\n",
        "            user_lines.append(f\"- [{ref.id}] {ref.text}\")\n",
        "\n",
        "    usr = \"\\n\".join(user_lines)\n",
        "\n",
        "    # 5. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®ä½œæˆ\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": augmented_sys_prompt},\n",
        "        {\"role\": \"user\", \"content\": usr},\n",
        "    ]\n",
        "\n",
        "# --- APIå‘¼ã³å‡ºã—ãƒ­ã‚¸ãƒƒã‚¯ã®å¾©å…ƒ ---\n",
        "def generate_outputs(samples: list[ExampleSample]) -> list[dict]:\n",
        "\n",
        "    # ãƒ€ãƒŸãƒ¼å‡¦ç†ã‚’é˜²ããŸã‚ã€OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã‚’è©¦è¡Œ\n",
        "    try:\n",
        "        # API_KEYã¯å¤–éƒ¨ã§å®šç¾©æ¸ˆã¿ã¨æƒ³å®š\n",
        "        client = OpenAI(api_key=API_KEY)\n",
        "        print(\"ğŸ“¢ APIå‘¼ã³å‡ºã—ã‚’é–‹å§‹ã—ã¾ã™ã€‚å®Ÿè¡Œã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™...\")\n",
        "    except NameError:\n",
        "        print(\"âŒ ã‚¨ãƒ©ãƒ¼: API_KEYã¾ãŸã¯OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚\")\n",
        "        return []\n",
        "\n",
        "    results: list[dict] = []\n",
        "\n",
        "    for sm in samples:\n",
        "        msgs = build_messages(sm)\n",
        "        try:\n",
        "            # æœ¬ç•ªç’°å¢ƒã®ãƒ­ã‚¸ãƒƒã‚¯: LLMã‚’å‘¼ã³å‡ºã—ã€Structured Outputã§ãƒ‘ãƒ¼ã‚¹\n",
        "            completion = client.chat.completions.parse(\n",
        "                model=MODEL_NAME,\n",
        "                messages=msgs,\n",
        "                temperature=TEMPERATURE,\n",
        "                response_format=GeneratedOutput,\n",
        "            )\n",
        "            parsed: GeneratedOutput = completion.choices[0].message.parsed  # type: ignore\n",
        "            steps = [\n",
        "                Step(id=s.id, text=s.text)\n",
        "                for s in sorted(parsed.procedure_steps, key=lambda x: x.id)\n",
        "            ][:50]\n",
        "        except Exception as e:\n",
        "            # APIå‘¼ã³å‡ºã—å¤±æ•—æ™‚ã®ã‚¨ãƒ©ãƒ¼å‡¦ç†\n",
        "            print(f\"âŒ ç”Ÿæˆå¤±æ•—: {sm.id}: {e}\")\n",
        "            steps = []\n",
        "        results.append({\n",
        "            \"id\": sm.id,\n",
        "            \"procedure_steps\": [{\"id\": s.id, \"text\": s.text} for s in steps],\n",
        "        })\n",
        "\n",
        "    if len(samples) > 0:\n",
        "      print(f\"âœ… ç”Ÿæˆå®Œäº†: {len(results)} samples\")\n",
        "      print(f\"ä¾‹: {results[0]['id']} â†’ {len(results[0]['procedure_steps'])} steps\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "# 'samples' å¤‰æ•°ãŒCell 5ä»¥å‰ã§ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’å‰æã¨ã—ã¾ã™ã€‚\n",
        "if 'samples' in globals():\n",
        "    generated_results = generate_outputs(samples)\n",
        "else:\n",
        "    print(\"âŒ ã‚¨ãƒ©ãƒ¼: æ¡ç‚¹ã«å¿…è¦ãª 'samples' å¤‰æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Cell 5ä»¥å‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
        "    generated_results = []\n",
        "\n",
        "# ç”Ÿæˆçµæœã‚’ JSONL ã§ä¿å­˜ã—ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’è¡¨ç¤º\n",
        "ts = time.strftime('%Y%m%d_%H%M%S')\n",
        "out_dir = Path('./outputs/runs')\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "jsonl_path = out_dir / f'generated_{ts}.jsonl'\n",
        "\n",
        "if generated_results:\n",
        "    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜\n",
        "    with jsonl_path.open('w', encoding='utf-8') as f:\n",
        "        for rec in generated_results:\n",
        "            obj = {\"id\": rec[\"id\"], \"output\": {\"procedure_steps\": rec[\"procedure_steps\"]}}\n",
        "            line = json.dumps(obj, ensure_ascii=False, separators=(\",\", \":\"))\n",
        "            f.write(line + \"\\n\")\n",
        "    print(f\"ğŸ“„ Saved JSONL: {jsonl_path}\")\n",
        "\n",
        "    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆColab/ãƒ­ãƒ¼ã‚«ãƒ«åŒæ–¹ã«å¯¾å¿œï¼‰\n",
        "    try:\n",
        "        from google.colab import files as colab_files  # type: ignore\n",
        "\n",
        "        # Colabç’°å¢ƒ: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’å¼·åˆ¶å®Ÿè¡Œ\n",
        "        print(f\"\\n--- â¬‡ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œä¸­ ---\")\n",
        "        print(f\"ãƒ•ã‚¡ã‚¤ãƒ«å: {jsonl_path.name}\")\n",
        "        colab_files.download(str(jsonl_path))\n",
        "        print(f\"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ã€‚ãŠä½¿ã„ã®PCã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
        "\n",
        "    except Exception:\n",
        "        # Colabç’°å¢ƒå¤–ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒãªã©ï¼‰: ãƒªãƒ³ã‚¯è¡¨ç¤º\n",
        "        from IPython.display import FileLink, display\n",
        "        print(f\"\\n--- ğŸ“„ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯ ---\")\n",
        "        display(FileLink(str(jsonl_path.resolve())))\n",
        "        print(\"ğŸ‘† ä¸Šè¨˜ã®ãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wYtMf3bJOzcN",
        "outputId": "dafef360-5bf4-427b-c06c-93b48a2efbdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¢ è©•ä¾¡ã‚’é–‹å§‹ã—ã¾ã™ã€‚10å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’æ¡ç‚¹ã—ã¾ã™...\n",
            "âœ… LLM-as-a-judge: Scored 10 samples (0-10)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               id  general_score  specific_score  total_score\n",
              "0   public_test_1            5.0             5.0         10.0\n",
              "1  public_test_10            5.0             5.0         10.0\n",
              "2   public_test_2            5.0             3.0          8.0\n",
              "3   public_test_3            5.0             3.0          8.0\n",
              "4   public_test_4            5.0             4.0          9.0\n",
              "5   public_test_5            4.0             0.0          4.0\n",
              "6   public_test_6            5.0             3.0          8.0\n",
              "7   public_test_7            5.0             4.0          9.0\n",
              "8   public_test_8            5.0             3.0          8.0\n",
              "9   public_test_9            5.0             5.0         10.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1dbd9133-81bb-44bf-afcf-26e9e0c702e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>general_score</th>\n",
              "      <th>specific_score</th>\n",
              "      <th>total_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>public_test_1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>public_test_10</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>public_test_2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>public_test_3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>public_test_4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>public_test_5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>public_test_6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>public_test_7</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>public_test_8</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>public_test_9</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1dbd9133-81bb-44bf-afcf-26e9e0c702e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1dbd9133-81bb-44bf-afcf-26e9e0c702e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1dbd9133-81bb-44bf-afcf-26e9e0c702e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5bb8de45-8311-4daf-ac5c-165fc7fff89e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5bb8de45-8311-4daf-ac5c-165fc7fff89e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5bb8de45-8311-4daf-ac5c-165fc7fff89e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\u274c \\u63a1\\u70b9\\u306b\\u5fc5\\u8981\\u306a 'samples' \\u307e\\u305f\\u306f 'generated_results' \\u5909\\u6570\\u304c\\u898b\\u3064\\u304b\\u308a\\u307e\\u305b\\u3093\\u3002Cell 5/6\\u3092\\u5b9f\\u884c\\u3057\\u3066\\u304f\\u3060\\u3055\\u3044\\u3002\\\")\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"public_test_8\",\n          \"public_test_10\",\n          \"public_test_5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"general_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3162277660168379,\n        \"min\": 4.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"specific_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.509230856356236,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.776388345929897,\n        \"min\": 4.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          8.0,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“„ Saved: outputs/runs/eval_llm_20251109_062620.csv\n",
            "\n",
            "--- â¬‡ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œä¸­ ---\n",
            "ãƒ•ã‚¡ã‚¤ãƒ«å: eval_llm_20251109_062620.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4db8e54e-a023-41dd-af1d-ed8fe4982c52\", \"eval_llm_20251109_062620.csv\", 1574)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ã€‚ãŠä½¿ã„ã®PCã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: LLM-as-a-judge è©•ä¾¡ï¼ˆ10ç‚¹æº€ç‚¹ï¼‰\n",
        "#@title 7. LLM ã§å…±é€š5ç‚¹ + å€‹åˆ¥5ç‚¹ã‚’æ¡ç‚¹ { display-mode: \"form\" }\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"OpenAI SDK v1 ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`uv add openai` ã§è¿½åŠ ã—ã¦ãã ã•ã„ã€‚\") from e\n",
        "\n",
        "try:\n",
        "    # Colabã§ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "    from google.colab import files as colab_files\n",
        "    from google.colab.output import eval_js\n",
        "except ImportError:\n",
        "    # Colabç’°å¢ƒå¤–ã®å ´åˆã¯ç„¡è¦–\n",
        "    pass\n",
        "\n",
        "JUDGE_MODEL = \"gpt-4o-2024-08-06\" # è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã‚’é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã«è¨­å®š\n",
        "JUDGE_TEMPERATURE = 0.2\n",
        "\n",
        "class JudgeOutput(BaseModel):\n",
        "    general_score: float = Field(ge=0, le=5)\n",
        "    specific_score: float = Field(ge=0, le=5)\n",
        "    final_score: float = Field(ge=0, le=10)\n",
        "    general_reason: str\n",
        "    specific_matches: List[str] = []\n",
        "    notes: Optional[str] = None\n",
        "\n",
        "def build_judge_messages(sample: ExampleSample, steps: List[Step]) -> list[dict]:\n",
        "    # è©•ä¾¡åŸºæº–ï¼ˆå…±é€š5ç‚¹ + å€‹åˆ¥5ç‚¹ï¼‰\n",
        "    system = (\n",
        "        \"ã‚ãªãŸã¯ç”Ÿå‘½ç§‘å­¦å®Ÿé¨“ã®å°‚é–€å®¶ã§ã‚ã‚Šã€å…¬å¹³ãªæ¡ç‚¹è€…ã§ã™ã€‚\"\n",
        "        \"ä»¥ä¸‹ã®åŸºæº–ã«å¾“ã£ã¦ã€ä¸ãˆã‚‰ã‚ŒãŸ Input ã¨ç”Ÿæˆæ‰‹é †ï¼ˆOutputï¼‰ã‚’è©•ä¾¡ã—ã€\"\n",
        "        \"general_score(0-5) ã¨ specific_score(0-5) ã¨ final_score(0-10) ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\"\n",
        "        \"\\n\\n[å…±é€šæ¡ç‚¹åŸºæº– 5ç‚¹æº€ç‚¹]\\n\"\n",
        "        \"åŠ ç‚¹(+1ãšã¤): 1) å®Ÿé¨“æŒ‡ç¤ºã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åæ˜ , 2) ä½¿ç”¨ã™ã‚‹ç‰©å“ã®åæ˜ , 3) å…ƒæ‰‹é †ã®è«–ç†åæ˜ , 4) æœŸå¾…ã•ã‚Œã‚‹æœ€çµ‚çŠ¶æ…‹ã®é”æˆ, 5) é©åˆ‡ãªè£œå®Œã€‚\\n\"\n",
        "        \"æ¸›ç‚¹: ä¸è‡ªç„¶ãªæ—¥æœ¬èª/ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³, è¨ˆç®—ãƒŸã‚¹, æ‰‹é †çŸ›ç›¾ã€‚\\n\"\n",
        "        \"ä¸Šé™: å…¥åŠ›æ‰‹é †ã®ä¸¸å†™ã—ç­‰ã®éåº¦ã®å®‰å…¨æ€§ãŒè¦‹ã‚‰ã‚Œã‚‹å ´åˆã€general_score ã¯æœ€å¤§2ç‚¹ã«åˆ¶é™ã€‚\\n\\n\"\n",
        "        \"[å€‹åˆ¥æ¡ç‚¹åŸºæº– 5ç‚¹æº€ç‚¹]\\n\"\n",
        "        \"ä¸ãˆã‚‰ã‚ŒãŸ specific_criteria ã®å„ item ãŒæ‰‹é †ã«å«ã¾ã‚Œã‚‹/æº€ãŸã™ãªã‚‰ã€ãã® score ã‚’åŠ ç‚¹ï¼ˆåˆè¨ˆ5ç‚¹ã§ä¸Šé™ï¼‰ã€‚\"\n",
        "    )\n",
        "\n",
        "    parts = []\n",
        "    parts.append(f\"ã€å®Ÿé¨“æŒ‡ç¤ºã€‘\\n{sample.input.instruction}\")\n",
        "    if sample.input.mandatory_objects:\n",
        "        parts.append(\"\\nã€ä½¿ç”¨ã™ã‚‹ç‰©å“ã€‘\")\n",
        "        for it in sorted(sample.input.mandatory_objects):\n",
        "            parts.append(f\"- {it}\")\n",
        "    if sample.input.source_protocol_steps:\n",
        "        parts.append(\"\\nã€å…ƒãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®æ‰‹é †ï¼ˆå‚è€ƒï¼‰ã€‘\")\n",
        "        for st in sample.input.source_protocol_steps:\n",
        "            parts.append(f\"- {st.id}. {st.text}\")\n",
        "    if sample.input.expected_final_states:\n",
        "        parts.append(\"\\nã€æœŸå¾…ã•ã‚Œã‚‹æœ€çµ‚çŠ¶æ…‹ã€‘\")\n",
        "        for fs in sorted(sample.input.expected_final_states):\n",
        "            parts.append(f\"- {fs}\")\n",
        "    if sample.input.references:\n",
        "        parts.append(\"\\nã€å‚è€ƒæ–‡çŒ®ã€‘\")\n",
        "        for ref in sample.input.references:\n",
        "            parts.append(f\"- [{ref.id}] {ref.text}\")\n",
        "\n",
        "    parts.append(\"\\nã€ç”Ÿæˆæ‰‹é †ï¼ˆOutputï¼‰ã€‘\")\n",
        "    for s in steps:\n",
        "        parts.append(f\"- {s.id}. {s.text}\")\n",
        "\n",
        "    parts.append(\"\\nã€specific_criteriaã€‘\")\n",
        "    if sample.measurement and sample.measurement.specific_criteria:\n",
        "        for item, sc in sample.measurement.specific_criteria.items():\n",
        "            parts.append(f\"- ({int(sc)}ç‚¹) {item}\")\n",
        "    else:\n",
        "        parts.append(\"- ãªã—\")\n",
        "\n",
        "    user = \"\\n\".join(parts)\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": user},\n",
        "    ]\n",
        "\n",
        "def judge_with_llm(samples: List[ExampleSample], generated: list[dict]) -> pd.DataFrame:\n",
        "    # API_KEYã®å­˜åœ¨ã‚’ç¢ºèª\n",
        "    if 'API_KEY' not in globals() or not globals()['API_KEY']:\n",
        "        print(\"âŒ API_KEYãŒæœªè¨­å®šã§ã™ã€‚æ¡ç‚¹å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
        "        return pd.DataFrame() # ç©ºã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¿”ã™\n",
        "\n",
        "    client = OpenAI(api_key=API_KEY)\n",
        "    proc_map = {g['id']: [Step(id=it['id'], text=it['text']) for it in g['procedure_steps']] for g in generated}\n",
        "    rows = []\n",
        "    quota_exhausted = False\n",
        "\n",
        "    print(f\"ğŸ“¢ è©•ä¾¡ã‚’é–‹å§‹ã—ã¾ã™ã€‚{len(samples)}å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’æ¡ç‚¹ã—ã¾ã™...\")\n",
        "\n",
        "    def _is_insufficient_quota(err: Exception) -> bool:\n",
        "        s = str(err).lower()\n",
        "        return 'insufficient_quota' in s or 'you exceeded your current quota' in s\n",
        "\n",
        "    for sm in samples:\n",
        "        if quota_exhausted:\n",
        "            print(f\"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—æ¡ç‚¹: {sm.id}ï¼ˆã‚¯ã‚©ãƒ¼ã‚¿ä¸è¶³ï¼‰\")\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': 0.0,\n",
        "                'specific_score': 0.0,\n",
        "                'total_score': 0.0,\n",
        "                'notes': 'skipped_due_to_quota',\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        # ç”Ÿæˆæ‰‹é †ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ¡ç‚¹ã‚¹ã‚­ãƒƒãƒ—\n",
        "        steps = proc_map.get(sm.id, [])\n",
        "        if not steps:\n",
        "            print(f\"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—æ¡ç‚¹: {sm.id}ï¼ˆç”Ÿæˆæ‰‹é †ãªã—ï¼‰\")\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': 0.0,\n",
        "                'specific_score': 0.0,\n",
        "                'total_score': 0.0,\n",
        "                'notes': 'skipped_no_generated_steps',\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        msgs = build_judge_messages(sm, steps)\n",
        "        try:\n",
        "            completion = client.chat.completions.parse(\n",
        "                model=JUDGE_MODEL,\n",
        "                messages=msgs,\n",
        "                temperature=JUDGE_TEMPERATURE,\n",
        "                response_format=JudgeOutput,\n",
        "            )\n",
        "            parsed: JudgeOutput = completion.choices[0].message.parsed  # type: ignore\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': parsed.general_score,\n",
        "                'specific_score': parsed.specific_score,\n",
        "                'total_score': parsed.final_score,\n",
        "                'notes': parsed.notes or '',\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ è©•ä¾¡å¤±æ•—: {sm.id}: {e}\")\n",
        "            if _is_insufficient_quota(e):\n",
        "                print(\"âš ï¸ APIã‚¯ã‚©ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ã€ä»¥é™ã®æ¡ç‚¹ã‚’ä¸­æ–­ã—ã¾ã™ã€‚ãƒ—ãƒ©ãƒ³/èª²é‡‘è¨­å®šã‚’ã”ç¢ºèªãã ã•ã„ã€‚\")\n",
        "                quota_exhausted = True\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': 0.0,\n",
        "                'specific_score': 0.0,\n",
        "                'total_score': 0.0,\n",
        "                'notes': 'evaluation_failed',\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "# 'samples'ã¨'generated_results'ãŒCell 6ã¾ã§ã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’å‰æã¨ã™ã‚‹\n",
        "if 'samples' in globals() and 'generated_results' in globals():\n",
        "    df = judge_with_llm(samples, generated_results)\n",
        "\n",
        "    if not df.empty:\n",
        "        print(f\"âœ… LLM-as-a-judge: Scored {len(df)} samples (0-10)\")\n",
        "        try:\n",
        "            # Colab/Jupyterç’°å¢ƒã§ã®DataFrameè¡¨ç¤º\n",
        "            display(df[['id','general_score','specific_score','total_score']])\n",
        "        except Exception:\n",
        "            # ãã®ä»–ç’°å¢ƒã§ã®å˜ç´”è¡¨ç¤º\n",
        "            print(df[['id','general_score','specific_score','total_score']])\n",
        "\n",
        "        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜\n",
        "        # 'out_dir'ã¨'ts'ãŒCell 6ã‹ã‚‰ç¶™ç¶šã—ã¦ã„ã‚‹ã“ã¨ã‚’å‰æã¨ã™ã‚‹\n",
        "        csv_path = out_dir / f'eval_llm_{ts}.csv'\n",
        "        df.to_csv(csv_path, index=False, encoding=\"utf_8_sig\")\n",
        "        print(f'ğŸ“„ Saved: {csv_path}')\n",
        "\n",
        "        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆColab/ãƒ­ãƒ¼ã‚«ãƒ«åŒæ–¹ã«å¯¾å¿œï¼‰\n",
        "        try:\n",
        "            # Colabç’°å¢ƒã®å ´åˆï¼ˆgoogle.colab.filesãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ï¼‰\n",
        "            if 'colab_files' in globals():\n",
        "                print(f\"\\n--- â¬‡ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œä¸­ ---\")\n",
        "                print(f\"ãƒ•ã‚¡ã‚¤ãƒ«å: {csv_path.name}\")\n",
        "                colab_files.download(str(csv_path))\n",
        "                print(f\"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ã€‚ãŠä½¿ã„ã®PCã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
        "            else:\n",
        "                 raise ImportError # Colabæ©Ÿèƒ½ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æ¬¡ã®exceptã¸\n",
        "\n",
        "        except Exception:\n",
        "            # Colabç’°å¢ƒå¤–ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒãªã©ï¼‰ã®å ´åˆ\n",
        "            from IPython.display import FileLink, display\n",
        "            print(f\"\\n--- ğŸ“„ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒªãƒ³ã‚¯ ---\")\n",
        "            display(FileLink(str(csv_path.resolve())))\n",
        "            print(\"ğŸ‘† ä¸Šè¨˜ã®ãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\")\n",
        "else:\n",
        "    print(\"âŒ æ¡ç‚¹ã«å¿…è¦ãª 'samples' ã¾ãŸã¯ 'generated_results' å¤‰æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Cell 5/6ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "la-bench",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}